{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f054a243-6457-4a87-955a-6c0661fa0d80",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d8ebda-9dc1-4763-87db-0e10c3ab7be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input, backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import csv\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9576988d-717e-486c-9a07-4c17449e826b",
   "metadata": {},
   "source": [
    "Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37121c3f-642c-4edc-b267-be199063eaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"/home/emizu/Desktop/SiamezeDataset\"\n",
    "MODEL_FILE = \"siamese_model.keras\"\n",
    "RESULTS_FILE = \"test_predictions.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9e32fe-8bf1-419d-ba0a-0deceb03f2c4",
   "metadata": {},
   "source": [
    "Set images resizeing(and thus nominal) sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a323763a-8275-47c6-9c0d-d3f9d65b9951",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 105\n",
    "IMG_WIDTH = 105\n",
    "IMG_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2892ee59-3c71-4b6a-913c-b98428cb7346",
   "metadata": {},
   "source": [
    "Function to load the dataset into a dictionary with person names(strings) as keys and image lists as values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa60c1b-7519-44e2-b659-2f5dc9cebddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset():\n",
    "    dataset = {}\n",
    "    for person in os.listdir(DATASET_DIR):\n",
    "        person_path = os.path.join(DATASET_DIR, person)\n",
    "        if os.path.isdir(person_path):\n",
    "            images = load_images_from_folder(person_path)\n",
    "            if len(images) > 1:\n",
    "                dataset[person] = images\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e9c890-2860-4755-b712-5490cb798619",
   "metadata": {},
   "source": [
    "Function to obtain all images of a person. It is meant to resize them, normalize them, group them into a list and return that list. An image is a tuple of the image label and actual image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f0a811-b125-4413-b17e-7ab313c4679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img_path = os.path.join(folder, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                # Resize image\n",
    "                img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "                # Normalize image to [0, 1]\n",
    "                img = img.astype(\"float32\") / 255.0\n",
    "                images.append((filename, img))\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fda1679-d1b4-4f1f-9bc3-6c140d2fe5c3",
   "metadata": {},
   "source": [
    "Function to split the dataset. Will return 1 subtataset in the form of 1 dictionary meant for live testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b64ab8-a346-40c8-bb3d-43089d7df39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset):\n",
    "    test_set = {}\n",
    "    for person, images in dataset.items():\n",
    "        random.shuffle(images)\n",
    "        n = len(images)\n",
    "        test_set[person] = images[int(0.8 * n):]\n",
    "    return test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad067a9-043f-4519-8d7f-93af204e8de4",
   "metadata": {},
   "source": [
    "Function to create pairs of images(tuples) from a dataset. Each pair will contain 2 images, a label(1 for pozitive pairs and 0 for negative pairs) and a metadata about the images(which is not fed into the model under any circumstance). The metadata is ment to serve as aditional informations when the output file is generated and for debuging purposes. \n",
    "A pozitive pair is a pair containing both images from the same person.\n",
    "A negative pair is a pair which contains 2 images of 2 different persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbe1e7e-1ccd-471b-b451-25753d582696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(data_dict):\n",
    "    positive_pairs = []\n",
    "    for person in data_dict:\n",
    "        images = data_dict[person]\n",
    "        for i in range(len(images)):\n",
    "            for j in range(i + 1, len(images)):\n",
    "                positive_pairs.append((images[i][1],images[j][1],1,(person, person, images[i][0], images[j][0])))\n",
    "\n",
    "    num_positive_pairs = len(positive_pairs)\n",
    "    negative_pairs = []\n",
    "    persons = list(data_dict.keys())\n",
    "\n",
    "    while len(negative_pairs) < num_positive_pairs:\n",
    "        person1 = random.choice(persons)\n",
    "        if not data_dict[person1]:\n",
    "            continue\n",
    "        fname1, img1 = random.choice(data_dict[person1])\n",
    "\n",
    "        other_persons = [p for p in persons if p != person1]\n",
    "        if not other_persons:\n",
    "            break  \n",
    "        person2 = random.choice(other_persons)\n",
    "        if not data_dict[person2]:\n",
    "            continue\n",
    "        fname2, img2 = random.choice(data_dict[person2])\n",
    "\n",
    "        negative_pairs.append((img1,img2,0,(person1, person2, fname1, fname2)))\n",
    "\n",
    "    all_pairs = positive_pairs + negative_pairs\n",
    "    random.shuffle(all_pairs)\n",
    "    return all_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5099ed-8068-4393-bbfa-ab6892dff8e9",
   "metadata": {},
   "source": [
    "Logical layer of the siamese network to compare the 2 inputs(their feature vectors).\n",
    "This layer needs to be specified also in this script as it's logic not memorized in the siamese network. \n",
    "Rather when creating and saving the siamese network, a refference towards the fact that a logical layer with the defined inputs and outputs should be linked is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68339e0-e81d-43e0-8842-4041f4443439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56db182e-22ea-4789-89e7-2a42d493df3f",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f32855-63d2-457a-a1f1-66410e7029dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MODEL_FILE):\n",
    "        print(f\"Model file {MODEL_FILE} not found. Exiting.\")\n",
    "        sys.exit(1)\n",
    "    print(\"Loading saved model...\")\n",
    "    model = load_model(MODEL_FILE, custom_objects={'euclidean_distance': euclidean_distance})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1446b8bc-6dad-45ea-977d-230dc982a6ad",
   "metadata": {},
   "source": [
    "Prepare the test dataset for live predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a45136c-b47c-4ef3-9e3e-b32b84a577eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading and preparing dataset for testing...\")\n",
    "dataset = prepare_dataset()\n",
    "if not dataset:\n",
    "    print(\"Dataset not found or no valid sub-folders/images. Exiting.\")\n",
    "        ys.exit(1)\n",
    "test_set = split_dataset(dataset)\n",
    "print(\"Creating test pairs...\")\n",
    "test_pairs = make_pairs(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ea0567-71a2-4422-bece-4da454d0f58c",
   "metadata": {},
   "source": [
    "Run the live predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad25f11f-5d66-422c-9892-210b4889e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running live predictions on test pairs...\")\n",
    "    predictions = []\n",
    "    for pair in test_pairs:\n",
    "        img1, img2, true_label, file_info = pair\n",
    "        img1_exp = np.expand_dims(img1, axis=0)\n",
    "        img2_exp = np.expand_dims(img2, axis=0)\n",
    "        pred = model.predict([img1_exp, img2_exp])[0][0]\n",
    "        predictions.append((file_info, true_label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd9ee8-c1fe-4b44-8aa5-1216e0d71722",
   "metadata": {},
   "outputs": [],
   "source": [
    "Save the predictions in a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a2eebc-0257-4cde-9396-3ce67801096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Saving predictions to {RESULTS_FILE} ...\")\n",
    "with open(RESULTS_FILE, mode='w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"Person1\", \"Person2\", \"File1\", \"File2\", \"TrueLabel\", \"Prediction\"])\n",
    "    for (file_info, true_label, pred) in predictions:\n",
    "        person1, person2, file1, file2 = file_info\n",
    "        writer.writerow([person1, person2, file1, file2, true_label, pred])\n",
    "\n",
    "print(\"Predictions saved to CSV.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
